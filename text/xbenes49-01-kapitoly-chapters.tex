%===============================================================================
% Autoři: Michal Bidlo, Bohuslav Křena, Jaroslav Dytrych, Petr Veigend a Adam Herout 2018

\chapter{Introduction}
\label{chapter:introduction}


Our~body as same as everything surrounding us emits some radiation. The~dominant wavelengths
belong to the~infrared spectrum and our body senses it as a heat. If we pass its significance
for living creatures and the~fact that the~presence of the~right amount of infrared radiation
is essencial for all the~life as we know it, there is also a~lot of usage in the~industry or
generally -- technology.

Infrared waves are used in various devices. From nightvision devices, astronomical telescopes to personal
electronics (infraport, TV remote controller). This thesis focuses on the usage in PIR
sensors -- electronic devices that changes its output based on the amount of received infrared
radiation.

The PIR sensors are used around us a lot even though we might not know it. We all know the waving
of hands towards the~sensor in a~hallway so the light would turn on and we could tie our shoes,
or the~self-opening door in shopping malls or self-rotating door in banks. These mechanisms mostly
use PIR sensors.

\begin{figure}[h!]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{obrazky-figures/automaticdoorway.jpg}
    \caption{PIR sensor: automatic doorway. \cite{automaticdoorway} \label{fig:automaticdoorway}}
  \end{center}
\end{figure}

PIR sensors offer even more than stating a presence of person. It is possible to~process sensor
output signal to~get more information about~sensed space - a~position of~person, a~number of~people.
Especially when more sensors are used.

The localization using PIR is still matter of intense research, a number of articles has been
written on it. This thesis suggests multisensor attitude and a usage of fuzzy logic to merge
sensor's outputs.



%\chapter{Abstract}
%\label{abstract}
%10 lines 
%Description of problem
%Solution and focus
%Maybe brief conclusion and application







\chapter{State of the art}
\label{theory}


\section{Physics of radiation}

In the~modelled system equations calculating with~infrared radiation are being used -- to~understand
them properly it is necessary to describe what is a~radiation, where does it come from and how can
we measure it. 

As it was already mentioned in the~chapter \ref{chapter:introduction}, every object whose temperature
is higher than absolute zero emits an~electromagnetic radiation.
\begin{equation}
T_{obj}>0~K\equiv -273.15^{\circ}C
\end{equation}
It is caused by a~charged subatomical particles (electrons, protons) that are undergoing an~acceleration,
emitting an~energy in a~form of photon -- electromagnetic radiation.


\subsection*{Characteristics}
The~electromagnetic radiation have a~number of measurable characteristics. The~most significant ones
are {\it frequency} $f$ and {\it wavelength} $\lambda$. Due to the~constant speed of the radiation $v$
aka speed of light $c = v = 3\cdot10^{8}~m\cdot s^{-1}$ not dependent on the frequency, they are
propotional and mutually transferrable.
\begin{equation}
f=\frac{v}{\lambda}=\frac{c}{\lambda}=\frac{3\cdot10^{8}}{\lambda}
\end{equation}

Electromagnetic waves are being divided into categories according to their usage by the wavelength
$\lambda$. With increasing wavelength~$\lambda$ it is gamma, X-rays, ultraviolet (UV), visible light,
infrared (IR) and radio waves. This is called electromagnetic spectrum and it is shown in the image
\ref{fig:spectrum}.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{obrazky-figures/spectrum.png}
\caption{Electromagnetic spectrum.\label{fig:spectrum}}
\end{center}    
\end{figure}

Another measurable characteristic is an~energy of the~radiation $Q$,$E$ or $W$. It is linearly dependend
on its frequency $f$ and can be computed using Planck constant $h=6.63\cdot10^{-34}~J\cdot s $.
\cite{NasaEMSpectrum}
\begin{equation}
W = h\cdot f
\end{equation}

The~power of the~radiation $\Phi$ is called {\it radiant power} or rather {\it radiant flux}. As a~regular
power it is energy per time, since the radiation is four-dimentional, partial derivations must be used.
\begin{equation}
\Phi = \frac{\partial W}{\partial t}
\end{equation}

The radiant power per unit surface is a~flux density. It is called either {\it radiant exitance} $M$
when emitting or {\it irradiance} $E$ when receiving.
\begin{subequations}
\begin{equation}
M = \frac{\partial \Phi_{emitted}}{\partial S_{sender}}
\end{equation}
\begin{equation}
E = \frac{\partial \Phi_{received}}{\partial S_{receiver}}
\end{equation}
\end{subequations}
The~Stefan-Boltzmann law defines irradiance of electromagnetic radiation as
\begin{equation}
I = \sigma \cdot T^4
\end{equation}
where $\sigma = 5.6704\cdot 10^{-8} Wm^{-2}K^{-4}$ is the~Stefan-Boltzmann constant and $T$ is a~thermodynamic
temperature.

Power per unit solid angle $I$ is called {\it radiant intensity}. With dividing by an~area of the~item
projected from certain direction we get an~amount of power emitted in that~direction called {\it radiance} $L$.
\begin{subequations}
\begin{equation}
I = \frac{\partial \Phi}{\partial \Omega}
\end{equation}
\begin{equation}
L = \frac{\partial I}{\partial S cos(\theta)}
\end{equation}
\end{subequations}
Other characteristics of radiation can be seen in the~table \ref{table:units}. \cite{iso800007} \cite{TemperatureMeasuring}

\begin{table}
\begin{tabular}{|c|c|c|l|} \hline
\textbf{Name}             & \textbf{Symbol} & \textbf{Unit}                 & \textbf{Definition}                             \\ \hline
Radiant flux        & $\Phi$          & $W$                           & Power transfered by a radiation.                \\ \hline
Radiant exitance    & $M$             & $W\cdot m^{-2}$               & Sent $W$ per sender's surface.                  \\ \hline 
Irradiance          & $E$             & $W\cdot m^{-2}$               & Received $W$ per receiver's surface.            \\ \hline
Radiant intensity   & $I$             & $W\cdot sr^{-1}$              & $W$ per unit solid angle.                       \\ \hline
Radiance            & $L$             & $W\cdot sr^{-1}\cdot m^{-2}$  & $I$ per sender's area projected to a direction. \\ \hline
\end{tabular}
\caption{Radiation characteristics.\label{table:units} \cite{TemperatureMeasuring}}
\end{table}



\newpage
\section{Temperature homeostasis}
The animal bodies require physical and chemical conditions in order to work properly (or at all). One of
the physical aspects is a temperature. There are generally three types of animals -- {\it ectotherms},
{\it endotherms} and {\it mesotherms}.

Ectotherms do not regulate its body temperature and rely on an external source, endotherms keeps it
constant independently on the environment, so called {\it homeothermy}\footnote{Homeothermy is an aspect
of homeostasis. It means keeping its inner body temperature within the preset limits.}. Mesotherm
strategy is then something in between.

Endotherm groups are birds and mammals, the most significant ectotherm group are reptiles. They compensate
it with basking in the sun. The thermal characteristics of these groups can be seen in the figure \ref{fig:thermoregulatory}.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.4\textwidth]{obrazky-figures/thermoregulatory.png}
\caption{Thermal regulation graph.\label{fig:thermoregulatory}\cite{thermoregulatory}}
\end{center}    
\end{figure}

Human body temperature $T_{HB}$ varies in $\langle 36^{\circ}C; 38^{\circ}C \rangle$, in the hyperthermia
it can rise up to $40^{\circ}C$. The figure \ref{fig:bodywavelength} shows the radiation wavelength composition.
The peak wavelength (temperature $37^{\circ}C$ or $310.15~K$) can be calculated with the Wien's displacement law.
\begin{equation}
\lambda_{max}=\frac{b}{T}=\frac{2.8977729 \cdot 10^{-3}}{310.15} = 9.3431~\mu m
\end{equation}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.4\textwidth]{obrazky-figures/bodyradiation.png}
\caption{Human body radiation wavelength.\cite{BodyRadiation}\label{fig:bodywavelength}}
\end{center}    
\end{figure}





\newpage
\section{Radiation perception}

\subsection*{Radiation processed by organisms}
This~thesis describes a~particular way how to use the~infrared radiation. Very important beginning of such
work is always studying existing applications. Unforgettable one is a~nature -- how evolution enabled 
various organisms to~use it.

Many animals can process parts of electromagnetic spectrum. Eyes enables mammals, cephalopods and arthropods
to sense a visible light, some insects can even see a~part of UV. Additionally organisms including human often
have thermoreceptors in~their skin so they can get information about intensity of infrared radiation around them.


\paragraph{Visible light}
\label{subsection:eye}
PIR~sensor structure is obviously inspired by a~human eye. Human eyes can process radiation
$\lambda \in \langle 380~nm;760~nm \rangle$ called visible light, one of the~bands of an~electromagnetic spectrum.
Seeing means receiving a light from a~light source reflected by the~surface of an~observed object to our retina.
A~biological system composed of~light-sensitive cells {\it rods} and {\it cones} propagates the~information
through nerves to brain.

A~ray coming to an~eye is going through a~converging lens, which changes its~trajectory aiming to~the~retina,
in~the~best case to~the~most sensitive place with a~lot~of~the~rods and cons called {\it Fovea~centralis}.
\cite{LightEyeVision}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.3\textwidth]{obrazky-figures/eye.png}
\caption{Structure of an eye. \cite{Eye}\label{fig:eye}}
\end{center}    
\end{figure}


\paragraph{Heat}
The~infrared rays surrounds us during our whole life, we sense it as~heat. The~heat receptors called
{\it thermoreceptors} in our body are located on its~surface (in the~skin), but also in~organs.
The~structure of~a~skin is shown in the figure \ref{fig:skin}. 

There is a~difference between sensing a~visible light and an~infrared radiation. Visible light comes
mostly reflected from the surface, while the IR can originate only from the~primary source -- warm item.

Our skin contains two types of~thermoreceptors: sensing cold, colder than a~body temperature and
hot, hotter than a~body temperature. The~skin structure is shown in~the~figure \ref{fig:skin}.
This is already well described, on the~other hand the~evaluation center of~these receptors in~the~brain
and its~mechanisms is~not fully understanded yet and a~matter of current research. \cite{BodilySenses}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.55\textwidth]{obrazky-figures/skin.jpg}
\caption{Structure of a~skin. \cite{SkinStructure}\label{fig:skin}}
\end{center}    
\end{figure}

Some animals even use sensing the heat as~a~primary way how to~survive. Several groups of~snakes
(pythons, rattlesnakes, boas and others) use it when hunting warm-blooded animals (mouses, rats, rabbits etc.).
Blood-eating organisms (vampire bats, south-american heteroptera {\it Triatoma infestans})
have IR receptors to~look for a~vein under the skin.\cite{SnakeInfrared}


\paragraph{Discovery}
For the~first time, the~infrared electromagnetic waves were observed and named in 1800 by German-English
astronome sir Frederick Harschel. He dispersed light by a~prism and found out that the~temperature
of~the~light is growing with wavelength, the~red light had the~highest one.

When he measured the~temperature behind the red light, there was no~visible light on~the~table but
the~thermometer was showing even higher temperature moving beyond~the~red spectrum. Harshel
pronounced hypothesis that except the~visible light there must be also invisible one which we can~not
see. \cite{HerschelLife}

%\begin{figure}[h!]
%\begin{center}
%\includegraphics[width=0.4\textwidth]{obrazky-figures/herschel.jpg}
%\caption{Sir William Herschel discovering the~infrared radiation.\cite{HerschelLife}\label{fig:herschel}}
%\end{center}    
%\end{figure}

A~great coincidence is that he was an~astronome, he even discovered the~planet Uran, and it is his discovery,
the~IR waves, which now enables us to~explore and understand the~universe. \cite{NasaIrVideo}



\subsection*{Infrared radiation processed by machines}
\label{IRsensing}
PIR ({\it passive infrared}) sensor is an electronic device that scans electromagnetic
radiation at~wavelength $\lambda\in \langle 700~nm;2.5~mm \rangle$ aka frequency $f\in \langle 120~MHz;430~THz \rangle$. \cite{an2105}

\paragraph{Principles of PIR sensor}
There is a~number of approaches how to~construct such a~sensor. The~point is to~convert the electromagnetic
energy in~electric voltage and send it away via wire to~be processed by~hardware or~software.

First way how to do it is {\it a~bolometer}. It uses the fact that resistance of a~resistor is different
when changing a~temperature, as shown in the equation \ref{eq:bolo} for temperature difference $\Delta T$
and resistor with original resistance $R_0$ and new resistance $R_t$ and with temperature coefficient $\alpha$.
So with using the~same voltage it measures the~electric current and with the~Ohm law $R = \frac{U}{I}$
the~sensor computes instantaneus resistance.

\begin{figure}[!ht]
\begin{equation}
R_t = R_0 (1 + \alpha\Delta T)
\end{equation}
\caption{Relationship of resistance and temperature.\label{eq:bolo}}
\end{figure}

Another type is {\it a thermoelectric sensor} reacting to the different thermoelectric resistance of
exposed wire and comparative wire.

The~last is {\it a~pyroelectric detector}. The~principle is based on~electrostatic polarization,
changing during the~temperature change. \cite{DetectorsBook}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.25\textwidth]{obrazky-figures/pirscheme.png}
\caption{Single element pyroelectric detector.\cite{an2105}\label{fig:pir}}
\end{center}    
\end{figure}


\paragraph{Sensing of the infrared radiation}
The~structure of~PIR sensor is inspirated by structure of an~eye described in~subsection \ref{subsection:eye}.
An infrared ray incoming to the~sensor first goes through~{\it Fresnel lens} aiming it onto~a~pyroelectric sensor
as you can see in the~figure \ref{fig:fresnellens}. Then the~ray is transformed in an~electric voltage.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.4\textwidth]{obrazky-figures/fresnellens.png}
\caption{Fresnel lens.\label{fig:fresnellens}}
\end{center}
\end{figure}

Before the output the signal is being processed. For vast majority of application we are interested in
people sensing emitting radiation characterized in the figure \ref{fig:bodywavelength}.
Therefore the signal is amplified and filtered to well discriminate their presence and absence.
An example is a scheme \ref{fig:pirstd} of product {\it PIR STD} made by {\it B+B Sensors}.

{\it Description of fresnel len of PIR STD.}



\newpage
\section{Pattern recognition}
The pattern recognition means processing of a signal and localizing of predefined objects.
The form is dependent on the type of signal and the objects that we search. Generally we can say
there are five parts of recognition pipeline.

\subsection*{Sensing}
In the world of digital computers sensing means {\it sampling}, converting a continuous signal
into discrete samples. It is present if the signal is being processed online.

Through different signal types various technologies for sensing are used -- image, sound, temperature,
pressure, weight, smell etc. The sensing procedure in the case of heat signal is described in the section
\ref{IRsensing}.

There is a few things that we need to deal during sensing: noise, linearity, callibration, ageing.

\subsection*{Segmentation}
The signal is splitted into segments by the time axis that are being processed separately. They can even overlap.
Segmentation ensures fast processing saving memory and other resources.

\subsection*{Features extraction}
Features are quantitive expression of the input signal, they replace the signal in the following phases.
Its purpose is to reduce memory and computational complexity of the processing. Each segment of $N$ samples
is transformed to vector of $K$ features, the point is to reduce dimensions, $K << N$, but preserve
relevant characteristics. Choosing the right features is therefore key for the following classifier.

To have good results the~features should be discriminative (distinguish between classes), invariant to
the transformations (translation, rotation, scale, deformation etc.) and decorrelated - mutually independent.

Vast number of described ways how to create features exists -- {\it Principal Component Analysis} (PCA),
{\it Linear Discriminant Analysis} (LDA). They can be used generally, but there is also many special
application-dependent features. 

\begin{figure}[h!]
\begin{center}
\includegraphics[width=1\textwidth]{obrazky-figures/featureextraction.png}
\caption{Components processing a signal before the classification itself.\label{fig:featureextraction}}
\end{center}
\end{figure}

Multiple thesis and articles were written on the topic of heat signal processing. For the feature extraction,
\cite{SinglePIR} suggests {\it Wavelet Transformation}, \cite{ChirpletSVM} uses {\it chirplet}-based features,
but also tests other feature-extraction methods: PCA, Expanded-Class LDA or fusion of PCA and LDA feature vectors,
\cite{BayesanClassifier} calculates with the signal itself.

\subsection*{Classification}
Before we will describe the classification phase, several terms must be defined: 
\begin{itemize}
\item {\it Detection} is a~classifying of presence of observed object or~characteristic.
\item {\it Identification} is an~assigning the~observed object to~one of~$N$ classes.
\item {\it Detection Error Tradeoff} is a~relation of~miss to~false alarm probability of~a~classifier.
The~goal is minimizing both with finding the~best settings of~classifier parameters.
\end{itemize}
This thesis performs a detection of~a~presence of~a~person. In~the~case of~positive detection identification
of~the~situation is made -- what was actually detected and whether it is a~person or more people etc.

Finding the~most suitable classifier for~the~task is fundamental, but consequent to the~feature extraction
method we use. At~the~end of~the~day, inputs of~all the~methods is a~vector of~features for~each segment.
There are linear and non-linear classifiers, separating the~hyperdimentional space into~segments. Then
the~segment is detected or identified if features vector geometrically lies in~the right segment. 

It is also possible to~perform some kind of transformation before classification if the~space is not separable
linearly. But other attitudes are also possible like algorithm {\it K-nearest neighbors}.

An~output of a~classifier can be either a~hard decision or some~kind of soft score, which can be later processed
by a~postprocessor -- used to merge data from~more classifiers or something else. A~classical linear classifier
is used in {\it Linear Regression} or {\it Support Vector Machine} (SVM). Each neuron of recently very popular
{\it Neural Networks} (NN) can also be represented with linear classifier.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.3\textwidth]{obrazky-figures/linear.png}
\caption{Linear classifier.\cite{LinearClassifier}\label{fig:linearclassifier}}
\end{center}
\end{figure}

\subsection*{Postprocessing}
During postprocessing different information than pattern are used, procedure is
connected to the concrete task. This parts often includes hard decision, if the
classifier's output is a soft score -- prices are taken into consideration,
the simpliest way is using treshold.



\chapter{Design Description}

The design of the whole project is separated in two modules - sensor module
and visualization program. Sensor module senses the observed space and does the
signal processing of outputs of connected PIR sensors. The data are then collected
and the fusion is made over them.

Results might be displayed in the visualization program. The data are being sent
over network. In the implementation, LAN is used, but it could be possible to
use the Internet and send the data to the remote visualizer.


\section{Sensor module}

Sensor module is a board with fixed sensors on it and a microcontroller performing the
classification process described in subsection \ref{label:dataprocessing}.

The sensors signal is at the end fused together and the results are classified objects
with coordinates in polar coordinate system relative to the module position. These
coordinates are sent to the client.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.5\textwidth]{obrazky-figures/design.png}
\caption{Geometry for three PIR sensors.\label{fig:design}}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.5\textwidth]{obrazky-figures/3pir_geometry.png}
\caption{Geometry for three PIR sensors.\label{fig:3pir_geometry}}
\end{center}
\end{figure}

The interior angle of module $\Omega$ is a parameter of the module construction. Using this parameter
orientation $\lambda$ and position $p_X = (d_X,\varphi _X)$\footnote{Position uses polar coordinates
with the origin in the central sensor.} of sensors can be expressed. Parameter $r$ is length
of module edges with sensor in the center. Sensor PIR-STD by B+B Sensors has $250\times 250\times 200~\text{mm}$;
therefore $r > 250~\text{mm}$.


\begin{subequations}
\begin{equation}
\lambda_C = 0
\end{equation}
\begin{equation}
\lambda_L = -\lambda_R = 180 - \Omega
\end{equation}
\end{subequations}

\begin{subequations}
\begin{equation}
\varphi_C = 0
\end{equation}
\begin{equation}
\varphi_L = -\varphi_R = 90 + \frac{180 - \Omega}{2}
\end{equation}
\end{subequations}

\begin{subequations}
\begin{equation}
d_C = 0
\end{equation}
\begin{equation}
d_L = d_R = \frac{r}{2} (r - 4cos(\Omega))
\end{equation}
\end{subequations}


\section{Data processing pipeline}
\label{label:dataprocessing}

The data path in the design is slightly inspired by classification phases except
there is fuzzification used here. It enables to create a fusion logic over vague
facts without need to evaluate them first.

\paragraph{Sensing}
Here we should think how to place sensor(s) in order to get the best results.
Interesting solution is suggested in \cite{GestureControl}. Three PIR sensors are
placed on solid board, as shown in the figure \ref{fig:3pir_geometry}.

This brings a great advantage -- not only it enables using of more sensors at one time, but
also it reduces the issue with positioning the sensors, since it is given by the
board construction.

The key here is to find the best value for $\Omega$ to minimize $r$, but maximize
$\varphi$. Low $r$ means more reliable results. High $\varphi$ increases measurable range.
Unfortunatelly these parameters are inversely propotional, a compromise needs to be done.

Now let's express both observed parameters with $\Omega$. A sensor has $250~mm$ to $250~mm$,
$o$ is a size of empty space on the sides of sensor, equation substituted $L = (12.5 + o)$.
\begin{subequations}
\begin{equation}
\varphi = 230 + \Omega
\end{equation}
\begin{equation}
r = \frac{sin((\frac{\Omega}{2}))L}{\tg{(\frac{\Omega}{2}-40)}} - cos((\frac{\Omega}{2}))L
\end{equation}
\end{subequations}

\subsection*{Segmentation}
The size of segments has a great influence on processing speed. And since the
result should run in the real time, it is quite important.

\subsection*{Features extractions}
Choosing good features is inevitable part of desing and the following classifier
is strictrly dependent on the form of features, since it is its input. Feature extraction
and fuzzification is implemented in the program {\it collector}.

The input is a vector of N samples and the process transforms them into the vector of
F features on the output.

\begin{figure}[!ht]
\begin{equation}
\Psi_s(x) = \begin{cases}
-1    & x \in \langle 0 ; \frac{s}{2} ) \\ 
1     & x \in \langle \frac{s}{2} ; s ) \\
0     & \text{otherwise}
\end{cases}
\end{equation}
\caption{Haar Wavelet.}
\end{figure}

\begin{figure}[!ht]
\begin{equation}
\Psi(x) = e^{-\frac{x^2}{2}} cos(5x)
\end{equation}
\caption{Morlet Wavelet.}
\end{figure}

\begin{figure}[!ht]
\begin{equation}
\Psi(x) = \frac{2^{\frac{5}{4}}}{\sqrt{3}}(1 + e^{2\pi x^2})e^{-\pi x^2}
\end{equation}
\caption{Mexican Hat Wavelet.}
\end{figure}

{\it Wavelet transformation for feature extraction}

\subsection*{Fuzzification and classification}
The classifier fuzzifies received a F-sized feature vector representing a segment of samples sensed by a sensor
into a 2D fuzzy values array. These values express fuzzy membership value of presence of a person.

Representation of the space in front of a sensor is inspired by cellular automata - carved into
segments. These segments are given by azimuth (phase) with a center in the sensor and by
the distance zone - deltas in polar coordinates.

Even though the space because of the construction of sensor has a shape of circular sector,
it can be easily represented by classical 2D matrix, as it is shown in the figure \ref{fig:circularsector}.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.7\textwidth]{obrazky-figures/circularsector_transformation.png}
\caption{Representation of circular sector.\label{fig:circularsector}}
\end{center}
\end{figure}

{\it Fuzzification. Consider action characteristics (speed, direction, multiple people).}

The output of fuzzification is a 2D matrix of space segments containing fuzzy value expressing
presence of person.

Using more sensors brings advantages: the measuring might be more precise since the person presence
classified by two independent sensors is not only more probable but the computed position
can get more accurate than when using only one sensor. The disadvantage is higher price and need
to know the mutual orientation and position of the sensors. 

If more sensors are used it is necessary to merge their space segments matrixes in one,
as shown in the figure \ref{fig:3pir_area}. To do so, a fuzzy logic mechanism
{\it Takagi-Sugeno rules} can be used as described in \cite{InsightIntoFuzzyModelling}.
The form of rules is [IF {\it antecendent} THEN {\it succendent}] as shown in the table
\ref{table:takagisugeno}. During the calculation all the antecendentes are evaluated
and the most relevant leads to application of corresponding succendent to the output.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.5\textwidth]{obrazky-figures/3pir_area.png}
\caption{Fusion of detection areas.\label{fig:3pir_area}}
\end{center}
\end{figure}

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|} \hline
\textbf{Rule}   & \textbf{Antecendent}                                & \textbf{Succendent}                             \\ \hline
$R_1$           & $X_1$ is $A_{11}$ and \dots and $X_n$ is $A_{1n}$   & $Y = b_{10} + b_{11}X_1 + \dots + b_{1n}X_n$    \\ \hline
$R_2$           & $X_1$ is $A_{21}$ and \dots and $X_n$ is $A_{2n}$   & $Y = b_{20} + b_{21}X_1 + \dots + b_{2n}X_n$    \\ \hline
\multicolumn{3}{|c|}{\dots}                                                                                             \\ \hline
$R_m$           & $X_1$ is $A_{m1}$ and \dots and $X_n$ is $A_{mn}$   & $Y = b_{m0} + b_{m1}X_1 + \dots + b_{mn}X_n$    \\ \hline
\end{tabular}
\caption{Takagi-Sugeno rules. $X$ is input, $A$ is a matrix of fuzzy numbers, $b$ is a matrix of fuzzy coefficients.\label{table:takagisugeno} \cite{InsightIntoFuzzyModelling}}
\end{center}
\end{table}

The designed fusion fuzzy system is to be seen in the table \ref{table:fuzzyfusion}. To be able to merge
the space segments, overlap must be known and then vector $X$ is created, containing pairs of values
from each vector ($X[i]_L$ and $X[i]_R$). Each of these pairs is input to the fusion algorithm, which
merges it to one fuzzy number result. 

$C_{L}$ and $C_{R}$ are 2D matrixes of coefficients with indexing $[i,j]$, where $i,j \in \{0,L,M,H\}$.
The fuzzy sets LOW, MEDIUM and HIGH of $X$ composes a basic evaluative trichotomy extended for unknown state OUT.
The optimal values of coefficients and the fuzzy sets parameters have to be found experimentally. 

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c c|rcl|} \hline
\textbf{Rule}   & \textbf{$X_L$}  & \textbf{$X_R$}  & \multicolumn{3}{|c|}{\textbf{Y}}  \\ \hline
$R_1$           & OUT             & OUT             & $C_{L}[0,0]    $&+&$ C_{R}[0,0]   $   \\ \hline
$R_2$           & OUT             & LOW             & $C_{L}[0,L]    $&+&$ C_{R}[L,0]X_R$   \\ \hline
$R_3$           & OUT             & MEDIUM          & $C_{L}[0,M]    $&+&$ C_{R}[M,0]X_R$   \\ \hline
$R_4$           & OUT             & HIGH            & $C_{L}[0,H]    $&+&$ C_{R}[H,0]X_R$   \\ \hline
$R_5$           & LOW             & OUT             & $C_{L}[L,0]X_L $&+&$ C_{R}[0,L]   $   \\ \hline
$R_6$           & LOW             & LOW             & $C_{L}[L,L]X_L $&+&$ C_{R}[L,L]X_R$   \\ \hline
$R_7$           & LOW             & MEDIUM          & $C_{L}[L,M]X_L $&+&$ C_{R}[M,L]X_R$   \\ \hline
$R_8$           & LOW             & HIGH            & $C_{L}[L,H]X_L $&+&$ C_{R}[H,L]X_R$   \\ \hline
$R_9$           & MEDIUM          & OUT             & $C_{L}[M,0]X_L $&+&$ C_{R}[0,M]$      \\ \hline
$R_{10}$        & MEDIUM          & LOW             & $C_{L}[M,L]X_L $&+&$ C_{R}[L,M]X_R$   \\ \hline
$R_{11}$        & MEDIUM          & MEDIUM          & $C_{L}[M,M]X_L $&+&$ C_{R}[M,M]X_R$   \\ \hline
$R_{12}$        & MEDIUM          & HIGH            & $C_{L}[M,H]X_L $&+&$ C_{R}[H,M]X_R$   \\ \hline
$R_{13}$        & HIGH            & OUT             & $C_{L}[H,0]X_L $&+&$ C_{R}[0,H]   $   \\ \hline
$R_{14}$        & HIGH            & LOW             & $C_{L}[H,L]X_L $&+&$ C_{R}[L,H]X_R$   \\ \hline
$R_{15}$        & HIGH            & MEDIUM          & $C_{L}[H,M]X_L $&+&$ C_{R}[M,H]X_R$   \\ \hline
$R_{16}$        & HIGH            & HIGH            & $C_{L}[H,H]X_L $&+&$ C_{R}[H,H]X_R$   \\ \hline
\end{tabular}
\caption{Design fuzzy system to fuseTakagi-Sugeno rules. $X$ is input, $A$ is a matrix of fuzzy numbers, $b$ is a matrix of fuzzy coefficients.\label{table:fuzzyfusion} \cite{InsightIntoFuzzyModelling}}
\end{center}
\end{table}

For three sectors as in the figure \ref{fig:3pir_area} the situation is analogous. The table also depends
on whether the areas of the side sensors overlap or not. Or they can be merged successively.

\subsection*{Defuzzification}

To get the results in a form of coordinate(s) of classified objects a cluster analysis is done. It calculates
a clusters of high membership values, for optimalization $\alpha$-cut on a certain level or tresholded
matrix can be used. Algorithm PAM (Partitioning Around Medoids is used), similar to k-means, where item called
medoid is used to represent the cluster instead of mean.

\begin{equation}
\mathit{PAM}(k, data) = argmin \left( \sum_{i=1}^{k} \sum_{j=1}^{k} ||data_{i} data_{j}||  \right)
\end{equation}

\begin{lstlisting}[style=python]
def PAM(k,data):
  # pick medoids
  medoids = [].generate(k,data.random())
  # compute dissimilarity matrix
  dm = DissimilarityMatrix(data,calculateDistance)
  # create clusters
  changed = True
  while changed:
    changed = False
    clusters = []
    for medoid_idx,medoid in medoids.enum():
      cluster = []
      for d in data:
        # add to cluster with closest distance to its medoid
        if dm[d,medoid] == dm[d,medoids].min():
          cluster.append(d)
      # set new center (SWAP phase)
      cluster.append(medoid)
      if medoid is not cluster.center():
        medoids[medoid_idx] = cluster.center()
        changed = True
      clusters.append(cluster)
  return clusters
\end{lstlisting}

\begin{lstlisting}[style=python]
function elbow(data):
  # try all k
  best = inf
  for k in <1,K_MAX>:
    clusters = PAM(data, k)
    # take minimal
    if WCSS(clusters) < best:
      best = clusters
  return best
\end{lstlisting}

To estimate the $k$, elbow method can be used: calculating k-means for different k values and taking the one with
minimal within-cluster sum of square (WCSS).\cite{ClusterAnalysis} \cite{VagueNatureInformation}

\begin{equation}
\mathit{WCSS} = \sum_{i=1}^{k} \sum_{x \in S_i} ||x - \mu_i||^2
\end{equation}

Very important is computing a distance of two segments. Since the original circular sector segmentation
is not homogenous, the distances varies with each distance. It can be calculated though using
cosine law. $P = (d, \alpha)$ is a segment given by polar coordinates, $d$ is distance and $\alpha$ is
azimuth.

\begin{equation}
|P_{1} P_{2}| = \sqrt{(d_{1})^{2} + (d_{2})^{2} - 2d_{1}d_{2}(\alpha_1 - \alpha_2)}
\end{equation}



\chapter{Data}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.85\textwidth]{obrazky-figures/signal_calm.png}
\caption{Signal of zero movement.\label{fig:signalcalm}}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.85\textwidth]{obrazky-figures/signal_walk.png}
\caption{Signal of person walking around.\label{fig:signalwalk}}
\end{center}
\end{figure}

A output of a sensor as you can see in the figures \ref{fig:signalcalm} and \ref{fig:signalwalk}
is very discriminative -- with a bare eye a movement from no movement is distinguishable.
A detection of presence used in light sensors can be implemented with tresholding, this attitude is
not very suitable for classification of anything else except the presence itself.

In a calm state the sensor sends a constant signal\footnote{Constant signal in the terms
of electricity, slightly polluted with a background noise etc.}. Movement in the sensed area causes
abrupt changes of output. When the object either leaves the area, or stays completely calm, the signal
changes are getting slower and after a little while the output voltage gets in the calm state again.

Therefore, the nature of the signal does not seem to need a complicated method to perform a classification on it.
{\it Fourier transformation} and {\it wavelet transformation} were considered for feature
extraction. The abrupt changes in the signal could be problem for FT, because it can not represent
it efficiently\cite{SinglePIR}, % youtube video
but unlike sinusoids, the wavelets exist for a finite duration and they are suitable for representing
abrupt changes.

The wavelet transformation is defined as a function F(s,k). Parameters s,k are scale and shift, changing
them in predefined unit and interval creates a matrix, as you can see in the figure \ref{fig:walk03}.

\begin{equation}
F(s,k) = \sum_{n=1}^{N} x[n] \Psi_{(s,k)}^{*}[n]
\end{equation}

Firstly The data were offline analysed using {\it Matlab}, which has implemented wavelet transformation.
The Matlab is not used because it is proprietary software and the program would be dependent on it.
During the analysis it was found, that the data are very well separable using continuous wavelet tranformation.

\begin{figure}[h!]
\begin{lstlisting}[style=matlab]
data = csvread('walk02.csv');
wscalogram('image', cwt(data));
\end{lstlisting}
\caption{Matlab code performing cwt.\label{list:cwtmatlab}}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.6\textwidth]{obrazky-figures/walk03.png}
\caption{Matlab {\it cwt()} output of {\it walk03.csv}.\label{fig:walk03}}
\end{center}
\end{figure}


{\it Origin of data, description, training.}




\chapter{Implementation}

\section{Module}

Nowadays most of the PIR sensors sold have only a binary output.
When signal reaches a set treshold output is set to logic "1" for a unit of time.
This mechanism is suitable for a light sensor or door sonsor, completely useless
for the needs of this project though.

The only found sensor that offers an analog output was {\it PIR STD} by
{\it B+B Sensors}. {\it Add documentation to appendix.}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.8\textwidth]{obrazky-figures/pirstd.png}
\caption{Scheme of PIR STD.\label{fig:pirstd}}
\end{center}
\end{figure}

The {\it PIR STD} scheme shown in the figure \ref{fig:pirstd} processes the signal
in three stages going from left to right. The first two processes the signal to analog output.
The third generates binary output from analog.

\paragraph{I. stage}
The first one starts at S of the PIR sensor, following with noise filter consisting of the
amplifier $U1A$ and the feedback components $R3$, $C4$, $C8$, $R14$, $C9$, $R14$.
There is also highpass filter done by $R6$ and $C3$. The output of this stage is a signal
with frequency between $f_{L1}$ and $f_{H1}$ amplified $A_{U1A}$ times.

\begin{equation}
f_{H1} = \frac{1}{2 \pi R_3 C_4}
\end{equation}

\begin{equation}
f_{L1} = \frac{1}{2 \pi R_6 C_3}
\end{equation}

\begin{equation}
A_{U1A} = 1 + \frac{R_3}{R_2}
\end{equation}

\paragraph{II. stage}
The second processing stage focuses on amplification. It also includes lowpass filtering done
by $C5$ and $R4$ and highpass filter performed by the feedback of amplifier $U1B$. The greater
amplification is also made by the divider bridge ($R8$, $R9$, $R10$, $R11$) connected to the
positive input. The output of frequency between $max(f_{L1}, f_{L2})$ and $min(f_{H1}, f_{H2})$
amplified $A_{U1A} \cdot A_{U1B}$ times is an analog output connected to the pin 1.

\begin{equation}
f_{H2} = \frac{1}{2 \pi R_5 C_6}
\end{equation}

\begin{equation}
f_{L2} = \frac{1}{2 \pi R_4 C_5}
\end{equation}

\begin{equation}
A_{U1B} = -\frac{R_5}{R_4}
\end{equation}

\paragraph{III. stage}
The third phase performs top-bottom tresholding generating binary output
used in simple industrial application. It is not used in the project.\cite{PIRSchemeDescription}

\subsection*{Programming of module}
The module is programmed to read signal in sampling frequency and send the data to server.

The usable sampling frequency can be estimated: the fresnel lens of {\it PIR STD} splits the
area into $10^{\circ}$ circular sectors. Object moving around the sensor in the distance $0.5~m$
with speed $15~km.h^{-1} = 4.1667~m.s^{-1}$ (very fast run) passes the central circular sector in

\begin{equation}
t = \frac{s}{v} = \frac{0.5*tg(10^{\circ})}{4.1667} = 0.02116~s
\end{equation}

This means the frequency of the movement through the circular sectors is

\begin{equation}
f = \frac{1}{t} = \frac{1}{0.02116} = 47.259~Hz
\end{equation}

According to Shannon theorem, the sampling frequency must be at least twice as big as the
maximal frequency in the signal, which leads to

\begin{equation}
Fs \geq 2*47.259 = 94.518 
\end{equation}

Rounding up gives us minimal sampling frequency $100~Hz$, or sampling period $10~ms$.
resulting with $2B$ sample in throughput $N$

\begin{equation}
N = F_s * |\text{sample}| * 8\frac{bit}{byte} = 100 * 2 * 8 = 1.6~kbps
\end{equation}


\section{Collector}
{\it Collector} is a program, as the name says, that collects data from sensors and implements
the whole described algorithm. Classified objects are then sent to a {\it visualizer}.

\subsection*{Communication}
The communication of the sensor module and the client app is designed as a client-server. The results
from the classification performed by server are sent to the client which shows it to user.

As the technology for the channel a LAN multicast stream is used at 224.0.0.128:12345.
The main advantage in comparison to unicast is a support of multiple clients.

\section{Visualizer}
Client app called {\it Visualizer} is written in {\it Python3} and graphical library {\it Tkinter}.
This choice was made with portability of the program taken into consideration.
The design of user interface is described in chapter \ref{Label:UI}.




\chapter{Experiments}
Unit tests were created to verify the program components. It uses {\it Boost.Test},
framework for creating unit tests which is part of {\it C++ Boost} library set.
The testing program placed in folder {\it collector/tests/} is linked with
{\it collector} transformed in static library.

{\it
Metodika a vysledky. Muze zahrnovat i matematicke dukazu, postupy...

Interpretace vysledku a moznosti nasazeni v praxi.

HW narocnost -- CPU, pamet, chovani pri paralelizaci apod.
}




\chapter{User Interface}
\label{Label:UI}

{\it Description of visualizer}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.6\textwidth]{obrazky-figures/visualizer.png}
\caption{Visualizer prototype with sample data. {\it Will be replaced.} \label{fig:visualizer}}
\end{center}
\end{figure}






\chapter{Conclusion}
Shrnuti zameru prace. Zhodnoceni splneni (i formalnich bodu).

Zhodnoceni z pohledu dalsiho vyvoje. Co se nestihlo (a dalo by se jeste).

Bez odkazu do textu / literatury. Zadne nove poznatky, cisla a grafy.

Pekny postreh k praci (co jsem se naucil).

Vyhled do budoucna, rozdeleni na casti.

20 stranek SEP, 40 bakalarka.




%===============================================================================
